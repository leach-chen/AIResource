
# ä¸€ã€æ¨¡å‹è½¬æ¢

## ğŸ“± ç§»åŠ¨ç«¯éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **TensorFlow Lite** | å®˜æ–¹æ”¯æŒå¥½ï¼Œç”Ÿæ€å®Œå–„ | è½¬æ¢å¯èƒ½æŸå¤±ç²¾åº¦ | å¤§å¤šæ•°Android/iOSåº”ç”¨ |
| **ONNX Runtime** | è·¨å¹³å°ï¼Œæ ¼å¼ç»Ÿä¸€ | åŒ…ä½“ç§¯è¾ƒå¤§ | éœ€è¦è·¨å¹³å°éƒ¨ç½² |
| **OpenCV DNN** | æ— éœ€é¢å¤–ä¾èµ–ï¼Œé›†æˆç®€å• | æ€§èƒ½ç›¸å¯¹è¾ƒä½ | å·²ä½¿ç”¨OpenCVçš„é¡¹ç›® |
| **PyTorch Mobile** | åŸç”ŸPyTorchæ”¯æŒ | ç”Ÿæ€ç›¸å¯¹è¾ƒæ–° | PyTorchæ¨¡å‹ç›´æ¥éƒ¨ç½² |
| **NCNN/MNN** | é’ˆå¯¹ç§»åŠ¨ç«¯ä¼˜åŒ– | å­¦ä¹ æˆæœ¬è¾ƒé«˜ | é«˜æ€§èƒ½è¦æ±‚çš„åº”ç”¨ |


## ğŸ”„ æ¨¡å‹è½¬æ¢æµç¨‹

### 1. PyTorch â†’ TensorFlow Lite
```python
# convert_to_tflite.py
import torch
import tensorflow as tf
import onnx
from onnx_tf.backend import prepare
import numpy as np

def pytorch_to_tflite(pytorch_model_path, tflite_output_path, input_shape=(1, 3, 640, 640)):
    """
    å°†PyTorch YOLOæ¨¡å‹è½¬æ¢ä¸ºTensorFlow Liteæ ¼å¼
    """
    
    # 1. åŠ è½½PyTorchæ¨¡å‹
    model = torch.load(pytorch_model_path, map_location='cpu')
    model.eval()
    
    # 2. å¯¼å‡ºä¸ºONNX
    dummy_input = torch.randn(*input_shape)
    onnx_path = pytorch_model_path.replace('.pt', '.onnx')
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},
        opset_version=12
    )
    print(f"ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ: {onnx_path}")
    
    # 3. ONNXè½¬TensorFlow SavedModel
    onnx_model = onnx.load(onnx_path)
    tf_rep = prepare(onnx_model)
    
    tf_savedmodel_path = pytorch_model_path.replace('.pt', '_savedmodel')
    tf_rep.export_graph(tf_savedmodel_path)
    print(f"TensorFlowæ¨¡å‹å¯¼å‡ºæˆåŠŸ: {tf_savedmodel_path}")
    
    # 4. SavedModelè½¬TensorFlow Lite
    converter = tf.lite.TFLiteConverter.from_saved_model(tf_savedmodel_path)
    
    # ä¼˜åŒ–é…ç½®
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]  # FP16é‡åŒ–ï¼Œå‡å°æ¨¡å‹å¤§å°
    
    # å¯¹äºYOLOæ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è‡ªå®šä¹‰æ“ä½œ
    converter.allow_custom_ops = True
    converter.experimental_new_converter = True
    
    tflite_model = converter.convert()
    
    # 5. ä¿å­˜TFLiteæ¨¡å‹
    with open(tflite_output_path, 'wb') as f:
        f.write(tflite_model)
    
    print(f"TensorFlow Liteæ¨¡å‹å¯¼å‡ºæˆåŠŸ: {tflite_output_path}")
    print(f"æ¨¡å‹å¤§å°: {len(tflite_model) / (1024*1024):.2f} MB")
    
    return tflite_output_path

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    pytorch_to_tflite(
        "yolov5s_dart.pt", 
        "yolov5s_dart.tflite",
        input_shape=(1, 3, 640, 640)
    )
```

### 2. PyTorch â†’ ONNXæ ¼å¼

```python
# convert_to_onnx.py
import torch
import onnx
import onnxsim

def export_yolo_onnx_simple(model_path, output_path, img_size=640):
    """
    ç®€åŒ–ç‰ˆYOLOæ¨¡å‹å¯¼å‡ºä¸ºONNX
    """
    model = torch.load(model_path, map_location='cpu')
    model.eval()
    
    # ç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(1, 3, img_size, img_size)
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        input_names=['images'],
        output_names=['output'],
        opset_version=12,
        dynamic_axes={
            'images': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    # ç®€åŒ–æ¨¡å‹
    model_onnx = onnx.load(output_path)
    model_simp, check = onnxsim.simplify(model_onnx)
    onnx.save(model_simp, output_path)
    
    print(f"ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ: {output_path}")

export_yolo_onnx_simple("yolov5s_dart.pt", "yolov5s_dart.onnx")
```

# äºŒã€ç§»åŠ¨ç«¯ä½¿ç”¨

## ğŸ¤– C++æ–¹å¼

### ä½¿ç”¨ OpenCV DNN ä¸ ONNX







## ğŸ¤– åŸç”Ÿæ–¹å¼

### ONNX æ–¹å¼

#### Androidç«¯ï¼š
```
// app/build.gradle
dependencies {
    implementation 'com.microsoft.onnxruntime:onnxruntime-android:1.15.1'
    
    // OpenCV for Androidï¼ˆç”¨äºå›¾åƒå¤„ç†ï¼‰
    implementation project(':opencv')
    // æˆ–è€…ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬
    // implementation 'com.quickbirdstudios:opencv:4.5.3.0'
}
```
#### IOSç«¯ï¼š
```
# Podfile
platform :ios, '12.0'

target 'DartMind' do
  pod 'onnxruntime-objc', '~> 1.15.0'
  
  # OpenCV
  pod 'OpenCV', '~> 4.5.0'
end
```


